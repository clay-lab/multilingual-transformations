clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_tu_de/neg_tu_de_train.json.gz --validation_file data/neg_tu/neg_tu_dev.json.gz --output_dir outputs/mt5-finetuning-neg-tu-de-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_de_tu/neg_de_tu_train.json.gz --validation_file data/neg_de/neg_de_dev.json.gz --output_dir outputs/mt5-finetuning-neg-de-tu-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_en_de/neg_en_de_train.json.gz --validation_file data/neg_en/neg_en_dev.json.gz --output_dir outputs/mt5-finetuning-neg-en-de-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_tu/neg_tu_train.json.gz --validation_file data/neg_tu/neg_tu_dev.json.gz --output_dir outputs/mt5-finetuning-neg-tu-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_en/neg_en_train.json.gz --validation_file data/neg_en/neg_en_dev.json.gz --output_dir outputs/mt5-finetuning-neg-en-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_en_tu/neg_en_tu_train.json.gz --validation_file data/neg_en/neg_en_dev.json.gz --output_dir outputs/mt5-finetuning-neg-en-tu-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_de_en/neg_de_en_train.json.gz --validation_file data/neg_de/neg_de_dev.json.gz --output_dir outputs/mt5-finetuning-neg-de-en-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_de/neg_de_train.json.gz --validation_file data/neg_de/neg_de_dev.json.gz --output_dir outputs/mt5-finetuning-neg-de-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
clear_hf_local_dataset_cache; module load CUDA; module load cuDNN; module load miniconda; source activate /gpfs/loomis/project/frank/ref4/conda_envs/py38; python models/run_seq2seq.py --model_name_or_path 'google/mt5-base' --do_train --task translation_src_to_tgt --train_file data/neg_tu_en/neg_tu_en_train.json.gz --validation_file data/neg_tu/neg_tu_dev.json.gz --output_dir outputs/mt5-finetuning-neg-tu-en-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
