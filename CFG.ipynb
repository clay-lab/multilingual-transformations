{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a021c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install nltk\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import json\n",
    "import gzip\n",
    "from typing import *\n",
    "import re\n",
    "from nltk import CFG, PCFG, Tree, nonterminals, Nonterminal, \\\n",
    "    Production\n",
    "import random\n",
    "from generator import generate\n",
    "#from generator import create_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b8c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d928ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | NP PP\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'a' | 'the'\n",
    "N -> 'dog' | 'cat'\n",
    "V -> 'chased' | 'sat'\n",
    "P -> 'on' | 'in'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "9ff848a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish_grammar = PCFG.fromstring(\"\"\"\n",
    "    S -> VP Person [.33]\n",
    "    S -> NP_nom1 VP Person1 [.23]\n",
    "    S -> NP_nom2 VP Person2 [.22]\n",
    "    S -> NP_nom3 VP Person3 [.22]\n",
    "    VP -> NP_acc V_trans [.5] | V_intrans [.5]\n",
    "    NP_nom1 -> 'ben' [1]\n",
    "    NP_nom2 -> 'sen' [1]\n",
    "    NP_nom3 -> 'o' [.4] | N [.6]\n",
    "    NP_acc -> N_obj '-i' [.8] | PP N_obj '-i' [.2]\n",
    "    PP -> N_place P [1]\n",
    "    P -> '-de-ki' [1]\n",
    "    N -> 'kedi' [.1] | 'köpek' [.1] | 'veteriner' [.1] | 'memur' [.1] | 'kraliçe' [.1] | 'başkan' [.1] | 'koyun' [.1] | 'yönetmen' [.1] | 'işçi' [.1] | ' balina' [.1]\n",
    "    N_obj -> ' yemek' [.1] | ' ekmek' [.1] | ' goril' [.1] | ' ayı' [.1] | ' eşek' [.1] | ' ördek' [.1] | ' oklukirpi' [.2] | ' gergeden' [.1] | ' maymun' [.1]\n",
    "    N_place -> ' masa' [.1] | ' sandalye' [.1] | ' yer' [.1] | ' kitap' [.1] | ' ev' [.1] | ' sokak' [.1] | ' oda' [.1] | ' köşe' [.1] | ' tavan' [.05] | ' kanape' [.05] | ' atölye' [.05] | ' deniz' [.05]\n",
    "    V_trans -> V_stem_trans Tense [1]\n",
    "    V_stem_trans -> ' iste' [.05] | ' sev' [.05] | ' ara' [.05]| ' gör' [.1] | ' siparış et' [.05] |' güven' [.05] | ' bul' [.05]| ' emret' [.05] |' tut'[.05]| ' kır'[.05]| ' affet'[.05]| ' özgür bırak' [.05]| ' tercih et'[.05]|' gözlemle' [.05]| ' sakla' [.05]| ' çal' [.05] | ' söv' [.05] | ' kurtar' [.05]| ' uyar' [.05]\n",
    "    Tense -> '-iyor' [.5] | '-di' [.25] | '-ecek' [.25]\n",
    "    Person -> Person1 [.2] | Person2 [.2] | Person3 [.6]\n",
    "    Person1 -> '-im' [1]\n",
    "    Person2 -> '-sin' [1]\n",
    "    Person3 -> '-' [1]\n",
    "    V_intrans -> V_stem_intrans Tense [1]\n",
    "    V_stem_intrans -> ' dinlen' [.05]| ' git' [.05] | ' öğren' [.05] |  ' izin ver' [.05]|' bekle' [.05]  | ' imdat iste' [.05] | ' özür dile'[.05] | ' oy ver' [.05] | ' gül' [.05] |' şikayet et'[.05]| ' övün'[.05]| ' şaşır'[.05] | ' acele et'[.05]| ' hata yap'[.05]| ' otur'[.05]| ' dur'[.05] | ' bağır' [.05]| ' not al'[.05] | ' yüz'[.05]| ' düşün'[.05]\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "ded68193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vh(expression):\n",
    "    expression = re.sub('(?<=u.)-i', 'u', expression)\n",
    "    expression = re.sub('(?<=a.)-i', 'ı', expression)\n",
    "    expression = re.sub('(?<=ı.)-i', 'ı', expression)\n",
    "    expression = re.sub('(?<=o.)-i', 'u', expression)\n",
    "    expression = re.sub('(?<=ü.)-i', 'ü', expression)\n",
    "    expression = re.sub('(?<=ö.)-i', 'ü', expression)\n",
    "#    expression = re.sub('(?<=e.)-i', 'u', expression)\n",
    "    \n",
    "#   expression = re.sub('(?<=s.)n', 'd', expression)\n",
    "    expression = re.sub('i-i', 'iyi', expression)\n",
    "#    expression = re.sub('a-iy', 'ıy', expression)\n",
    "   \n",
    "    expression = re.sub('a-i', 'ayı', expression)\n",
    "    expression = re.sub('ı-i', 'ıyı', expression)\n",
    "\n",
    "\n",
    "    \n",
    "    expression = re.sub('i-l', 'iyl', expression)\n",
    "    expression = re.sub('e-l', 'eyl', expression)\n",
    "    expression = re.sub('ü-l', 'üyl', expression)\n",
    "    expression = re.sub('ö-l', 'öyl', expression)\n",
    "\n",
    "    expression = re.sub('ı-le', 'iyla', expression)\n",
    "    expression = re.sub('a-le', 'ayla', expression)\n",
    "    expression = re.sub('u-le', 'uyla', expression)\n",
    "    expression = re.sub('o-le', 'oyla', expression)\n",
    "\n",
    "\n",
    "\n",
    "    expression = re.sub('(?<=ü.)-di', 'dü', expression)\n",
    "    expression = re.sub('(?<=ö.)-di', 'dü', expression)\n",
    "    expression = re.sub('(?<=a.)-di', 'dı', expression)\n",
    "    expression = re.sub('(?<=ı.)-di', 'dı', expression)\n",
    "    expression = re.sub('(?<=u.)-di', 'du', expression)\n",
    "    expression = re.sub('(?<=i.)-di', 'di', expression)\n",
    "    expression = re.sub('(?<=e.)-di', 'di', expression)\n",
    "    expression = re.sub('(?<=o.)-di', 'du', expression)\n",
    "    \n",
    "    expression = re.sub('(?<=ü.)-iyor', 'üyor', expression)\n",
    "    expression = re.sub('(?<=ö.)-iyor', 'üyor', expression)\n",
    "    expression = re.sub('(?<=a.)-iyor', 'ıyor', expression)\n",
    "    expression = re.sub('(?<=ı.)-iyor', 'ıyor', expression)\n",
    "    expression = re.sub('(?<=u.)-iyor', 'uyor', expression)\n",
    "    expression = re.sub('(?<=i.)-iyor', 'iyor', expression)\n",
    "    expression = re.sub('(?<=e.)-iyor', 'iyor', expression)\n",
    "    expression = re.sub('(?<=o.)-iyor', 'uyor', expression)\n",
    "\n",
    "    expression = re.sub('a-di', 'adı', expression)\n",
    "    expression = re.sub('a-iyor', 'ıyor', expression)\n",
    "\n",
    "    expression = re.sub('e-di', 'edi', expression)\n",
    "    expression = re.sub('e-iyor', 'iyor', expression)\n",
    "\n",
    "    expression = re.sub('e-ecek', 'eyecek', expression)\n",
    "    expression = re.sub('a-ecek', 'ayacak', expression)\n",
    "\n",
    "    expression = re.sub('(?<=ü.)-ecek', 'ecek', expression)\n",
    "    expression = re.sub('(?<=ö.)-ecek', 'ecek', expression)\n",
    "    expression = re.sub('(?<=a.)-ecek', 'acak', expression)\n",
    "    expression = re.sub('(?<=ı.)-ecek', 'acak', expression)\n",
    "    expression = re.sub('(?<=u.)-ecek', 'acak', expression)\n",
    "    expression = re.sub('(?<=i.)-ecek', 'ecek', expression)\n",
    "    expression = re.sub('(?<=e.)-ecek', 'ecek', expression)\n",
    "    expression = re.sub('(?<=o.)-ecek', 'acak', expression)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    expression = re.sub('k-i', 'ği', expression)\n",
    "#    expression = re.sub('di-sin', 'din', expression)\n",
    "    expression = re.sub('ör-i', 'örü', expression)\n",
    "#    expression = re.sub('ör-di', 'ördü', expression)\n",
    "#    expression = re.sub('a-di', 'adı', expression)\n",
    "    expression = re.sub('t-d', 'tt', expression)\n",
    "    expression = re.sub('k-d', 'kt', expression)\n",
    "\n",
    "    expression = re.sub('td', 'tt', expression)\n",
    "    expression = re.sub('kd', 'kt', expression)\n",
    "\n",
    "\n",
    "    expression = re.sub('ap-de', 'apta', expression)\n",
    "\n",
    "    expression = re.sub('t-i', 'di', expression)\n",
    "    expression = re.sub('a-de-ki', 'adaki', expression)\n",
    "    expression = re.sub('ei', 'i', expression)\n",
    "    expression = re.sub('aı', 'ı', expression)\n",
    "    expression = re.sub('aı', 'ı', expression)\n",
    "    expression = re.sub('gite', 'gide', expression)\n",
    "    expression = re.sub('ete', 'ede', expression)\n",
    "\n",
    "\n",
    "\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "0f745f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vh_n(expression):\n",
    "    expression = re.sub('(?<=u.)-i', 'u', expression)\n",
    "    expression = re.sub('(?<=a.)-i', 'ı', expression)\n",
    "    expression = re.sub('(?<=ı.)-i', 'ı', expression)\n",
    "    expression = re.sub('(?<=o.)-i', 'u', expression)\n",
    "    expression = re.sub('(?<=ü.)-i', 'ü', expression)\n",
    "    expression = re.sub('(?<=ö.)-i', 'ü', expression)\n",
    "#    expression = re.sub('(?<=e.)-i', 'u', expression)\n",
    "    \n",
    "#   expression = re.sub('(?<=s.)n', 'd', expression)\n",
    "    expression = re.sub('i-i', 'iyi', expression)\n",
    "#    expression = re.sub('a-iy', 'ıy', expression)\n",
    "   \n",
    "    expression = re.sub('a-i', 'ayı', expression)\n",
    "    expression = re.sub('ı-i', 'ıyı', expression)\n",
    "\n",
    "\n",
    "    expression = re.sub('i-l', 'iyl', expression)\n",
    "    expression = re.sub('e-l', 'eyl', expression)\n",
    "    expression = re.sub('ü-l', 'üyl', expression)\n",
    "    expression = re.sub('ö-l', 'öyl', expression)\n",
    "\n",
    "    expression = re.sub('ı-le', 'iyla', expression)\n",
    "    expression = re.sub('a-le', 'ayla', expression)\n",
    "    expression = re.sub('u-le', 'uyla', expression)\n",
    "    expression = re.sub('o-le', 'oyla', expression)\n",
    "\n",
    "\n",
    "\n",
    "    expression = re.sub('(?<=ü.)-m--di', 'medi', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--di', 'medi', expression)\n",
    "    expression = re.sub('(?<=a.)-m--di', 'madı', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--di', 'madı', expression)\n",
    "    expression = re.sub('(?<=u.)-m--di', 'madı', expression)\n",
    "    expression = re.sub('(?<=i.)-m--di', 'medi', expression)\n",
    "    expression = re.sub('(?<=e.)-m--di', 'medi', expression)\n",
    "    expression = re.sub('(?<=o.)-m--di', 'madı', expression)\n",
    "    \n",
    "    expression = re.sub('(?<=ü.)-m--iyor', 'müyor', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--iyor', 'müyor', expression)\n",
    "    expression = re.sub('(?<=a.)-m--iyor', 'mıyor', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--iyor', 'mıyor', expression)\n",
    "    expression = re.sub('(?<=u.)-m--iyor', 'muyor', expression)\n",
    "    expression = re.sub('(?<=i.)-m--iyor', 'miyor', expression)\n",
    "    expression = re.sub('(?<=e.)-m--iyor', 'miyor', expression)\n",
    "    expression = re.sub('(?<=o.)-m--iyor', 'muyor', expression)\n",
    "\n",
    "    expression = re.sub('a-m--di', 'amadı', expression)\n",
    "    expression = re.sub('a-m--iyor', 'amıyor', expression)\n",
    "\n",
    "    expression = re.sub('e-m--di', 'emedi', expression)\n",
    "    expression = re.sub('e-m--iyor', 'emiyor', expression)\n",
    "    \n",
    "    expression = re.sub('e-m--ecek', 'emeyecek', expression)\n",
    "    expression = re.sub('a-m--ecek', 'amayacak', expression)\n",
    "\n",
    "    expression = re.sub('(?<=ü.)-m--ecek', 'meyecek', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--ecek', 'meyecek', expression)\n",
    "    expression = re.sub('(?<=a.)-m--ecek', 'mayacak', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--ecek', 'mayacak', expression)\n",
    "    expression = re.sub('(?<=u.)-m--ecek', 'mayacak', expression)\n",
    "    expression = re.sub('(?<=i.)-m--ecek', 'meyecek', expression)\n",
    "    expression = re.sub('(?<=e.)-m--ecek', 'meyecek', expression)\n",
    "    expression = re.sub('(?<=o.)-m--ecek', 'mayacak', expression)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    expression = re.sub('k-i', 'ği', expression)\n",
    "#    expression = re.sub('di-sin', 'din', expression)\n",
    "    expression = re.sub('ör-i', 'örü', expression)\n",
    "#    expression = re.sub('ör-di', 'ördü', expression)\n",
    "#    expression = re.sub('a-di', 'adı', expression)\n",
    "    expression = re.sub('t-d', 'tt', expression)\n",
    "    expression = re.sub('k-d', 'kt', expression)\n",
    "\n",
    "    expression = re.sub('td', 'tt', expression)\n",
    "    expression = re.sub('kd', 'kt', expression)\n",
    "\n",
    "\n",
    "    expression = re.sub('ap-de', 'apta', expression)\n",
    "\n",
    "    expression = re.sub('t-i', 'di', expression)\n",
    "    expression = re.sub('a-de-ki', 'adaki', expression)\n",
    "    expression = re.sub('ei', 'i', expression)\n",
    "    expression = re.sub('aı', 'ı', expression)\n",
    "    expression = re.sub('aı', 'ı', expression)\n",
    "    expression = re.sub('gite', 'gide', expression)\n",
    "    expression = re.sub('ete', 'ede', expression)\n",
    "\n",
    "\n",
    "\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "c5b1dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodash(expression):\n",
    "    \n",
    "    expression = re.sub('-', '', expression)\n",
    "    return expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ea165339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vh2(expression):\n",
    "    expression = re.sub('-', '', expression)\n",
    "    expression = re.sub('p-d', 'pt', expression)\n",
    "    expression = re.sub('sd', 'st', expression)\n",
    "    expression = re.sub('etiyor', 'ediyor', expression)\n",
    "    expression = re.sub('etece', 'edece', expression)\n",
    " #   expression = re.sub('a-ecek', 'ayacak', expression)\n",
    "    expression = re.sub('itiyor', 'idiyor', expression)\n",
    "    expression = re.sub('^\\s', '', expression)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "9b583449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowelharmony(expression):\n",
    "#    expression = re.sub('di-im', 'di-m', expression)\n",
    "#    expression = re.sub('di-sin', 'di-n', expression)\n",
    "    expression = re.sub('(?<=ü.)-di-sin', 'dün', expression)\n",
    "    expression = re.sub('(?<=ö.)-di-sin', 'dün', expression)\n",
    "    expression = re.sub('(?<=a.)-di-sin', 'dın', expression)\n",
    "    expression = re.sub('(?<=ı.)-di-sin', 'dın', expression)\n",
    "    expression = re.sub('(?<=u.)-di-sin', 'dun', expression)\n",
    "    expression = re.sub('(?<=i.)-di-sin', 'din', expression)\n",
    "    expression = re.sub('(?<=e.)-di-sin', 'din', expression)\n",
    "    expression = re.sub('(?<=o.)-di-sin', 'dun', expression)\n",
    "    expression = re.sub('(?<=ü.)-di-im', 'düm', expression)\n",
    "    expression = re.sub('(?<=ö.)-di-im', 'düm', expression)\n",
    "    expression = re.sub('(?<=a.)-di-im', 'dım', expression)\n",
    "    expression = re.sub('(?<=ı.)-di-im', 'dım', expression)\n",
    "    expression = re.sub('(?<=u.)-di-im', 'dum', expression)\n",
    "    expression = re.sub('(?<=i.)-di-im', 'dim', expression)\n",
    "    expression = re.sub('(?<=e.)-di-im', 'dim', expression)\n",
    "    expression = re.sub('(?<=o.)-di-im', 'dum', expression)\n",
    "    \n",
    "    expression = re.sub('(?<=ü.)-iyor-sin', 'üyorsun', expression)\n",
    "    expression = re.sub('(?<=ö.)-iyor-sin', 'üyorsun', expression)\n",
    "    expression = re.sub('(?<=a.)-iyor-sin', 'ıyorsun', expression)\n",
    "    expression = re.sub('(?<=ı.)-iyor-sin', 'ıyorsun', expression)\n",
    "    expression = re.sub('(?<=u.)-iyor-sin', 'uyorsun', expression)\n",
    "    expression = re.sub('(?<=i.)-iyor-sin', 'iyorsun', expression)\n",
    "    expression = re.sub('(?<=e.)-iyor-sin', 'iyorsun', expression)\n",
    "    expression = re.sub('(?<=o.)-iyor-sin', 'uyorsun', expression)\n",
    "    expression = re.sub('(?<=ü.)-iyor-im', 'üyorum', expression)\n",
    "    expression = re.sub('(?<=ö.)-iyor-im', 'üyorum', expression)\n",
    "    expression = re.sub('(?<=a.)-iyor-im', 'ıyorum', expression)\n",
    "    expression = re.sub('(?<=ı.)-iyor-im', 'ıyorum', expression)\n",
    "    expression = re.sub('(?<=u.)-iyor-im', 'uyorum', expression)\n",
    "    expression = re.sub('(?<=i.)-iyor-im', 'iyorum', expression)\n",
    "    expression = re.sub('(?<=e.)-iyor-im', 'iyorum', expression)\n",
    "    expression = re.sub('(?<=o.)-iyor-im', 'uyorum', expression)\n",
    "    \n",
    "\n",
    "    expression = re.sub('(?<=ü.)-ecek-sin', 'eceksin', expression)\n",
    "    expression = re.sub('(?<=ö.)-ecek-sin', 'eceksin', expression)\n",
    "    expression = re.sub('(?<=a.)-ecek-sin', 'acaksın', expression)\n",
    "    expression = re.sub('(?<=ı.)-ecek-sin', 'acaksın', expression)\n",
    "    expression = re.sub('(?<=u.)-ecek-sin', 'acaksın', expression)\n",
    "    expression = re.sub('(?<=i.)-ecek-sin', 'eceksin', expression)\n",
    "    expression = re.sub('(?<=e.)-ecek-sin', 'eceksin', expression)\n",
    "    expression = re.sub('(?<=o.)-ecek-sin', 'acaksın', expression)\n",
    "    expression = re.sub('(?<=ü.)-ecek-im', 'eceğim', expression)\n",
    "    expression = re.sub('(?<=ö.)-ecek-im', 'eceğim', expression)\n",
    "    expression = re.sub('(?<=a.)-ecek-im', 'acağım', expression)\n",
    "    expression = re.sub('(?<=ı.)-ecek-im', 'acağım', expression)\n",
    "    expression = re.sub('(?<=u.)-ecek-im', 'acağım', expression)\n",
    "    expression = re.sub('(?<=i.)-ecek-im', 'eceğim', expression)\n",
    "    expression = re.sub('(?<=e.)-ecek-im', 'eceğim', expression)\n",
    "    expression = re.sub('(?<=o.)-ecek-im', 'acağım', expression)\n",
    "    \n",
    "    expression = re.sub('a-di-im', 'adım', expression)\n",
    "    expression = re.sub('a-di-sin', 'adın', expression)\n",
    "    expression = re.sub('a-iyor-sin', 'ıyorsun', expression)\n",
    "    expression = re.sub('a-iyor-im', 'ıyorum', expression)\n",
    "\n",
    "    expression = re.sub('e-di-im', 'edim', expression)\n",
    "    expression = re.sub('e-di-sin', 'edin', expression)\n",
    "    expression = re.sub('e-iyor-sin', 'iyorsun', expression)\n",
    "    expression = re.sub('e-iyor-im', 'iyorum', expression)\n",
    "\n",
    "    \n",
    "    expression = re.sub('a-ecek-sin', 'ayacaksın', expression)\n",
    "    expression = re.sub('e-ecek-sin', 'eyeceksin', expression)\n",
    "\n",
    "    expression = re.sub('a-ecek-im', 'ayacağım', expression)\n",
    "    expression = re.sub('e-ecek-im', 'eyeceğim', expression)\n",
    "\n",
    "\n",
    "\n",
    "#    expression = re.sub('e-ec', 'eyec', expression)\n",
    "#    expression = re.sub('a-ecek', 'ayacak', expression)\n",
    "\n",
    "    expression = re.sub('or-im', 'orum', expression)\n",
    "    expression = re.sub('or-sin', 'orsun', expression)\n",
    "#    expression = re.sub('un-iy', 'unu', expression)\n",
    "    expression = re.sub('un-di', 'undu', expression)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return vh2((vh(expression)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "952d51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowelharmony_n(expression):\n",
    "#    expression = re.sub('di-im', 'di-m', expression)\n",
    "#    expression = re.sub('di-sin', 'di-n', expression)\n",
    "    expression = re.sub('(?<=ü.)-m--di-sin', 'medin', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--di-sin', 'medin', expression)\n",
    "    expression = re.sub('(?<=a.)-m--di-sin', 'madın', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--di-sin', 'madın', expression)\n",
    "    expression = re.sub('(?<=u.)-m--di-sin', 'madın', expression)\n",
    "    expression = re.sub('(?<=i.)-m--di-sin', 'medin', expression)\n",
    "    expression = re.sub('(?<=e.)-m--di-sin', 'medin', expression)\n",
    "    expression = re.sub('(?<=o.)-m--di-sin', 'madın', expression)\n",
    "    expression = re.sub('(?<=ü.)-m--di-im', 'medim', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--di-im', 'medim', expression)\n",
    "    expression = re.sub('(?<=a.)-m--di-im', 'madım', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--di-im', 'madım', expression)\n",
    "    expression = re.sub('(?<=u.)-m--di-im', 'madım', expression)\n",
    "    expression = re.sub('(?<=i.)-m--di-im', 'medim', expression)\n",
    "    expression = re.sub('(?<=e.)-m--di-im', 'medim', expression)\n",
    "    expression = re.sub('(?<=o.)-m--di-im', 'madım', expression)\n",
    "    \n",
    "    expression = re.sub('(?<=ü.)-m--iyor-sin', 'müyorsun', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--iyor-sin', 'müyorsun', expression)\n",
    "    expression = re.sub('(?<=a.)-m--iyor-sin', 'mıyorsun', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--iyor-sin', 'mıyorsun', expression)\n",
    "    expression = re.sub('(?<=u.)-m--iyor-sin', 'muyorsun', expression)\n",
    "    expression = re.sub('(?<=i.)-m--iyor-sin', 'miyorsun', expression)\n",
    "    expression = re.sub('(?<=e.)-m--iyor-sin', 'miyorsun', expression)\n",
    "    expression = re.sub('(?<=o.)-m--iyor-sin', 'muyorsun', expression)\n",
    "    expression = re.sub('(?<=ü.)-m--iyor-im', 'müyorum', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--iyor-im', 'müyorum', expression)\n",
    "    expression = re.sub('(?<=a.)-m--iyor-im', 'mıyorum', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--iyor-im', 'mıyorum', expression)\n",
    "    expression = re.sub('(?<=u.)-m--iyor-im', 'muyorum', expression)\n",
    "    expression = re.sub('(?<=i.)-m--iyor-im', 'miyorum', expression)\n",
    "    expression = re.sub('(?<=e.)-m--iyor-im', 'miyorum', expression)\n",
    "    expression = re.sub('(?<=o.)-m--iyor-im', 'muyorum', expression)\n",
    "    \n",
    "\n",
    "    expression = re.sub('(?<=ü.)-m--ecek-sin', 'meyeceksin', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--ecek-sin', 'meyeceksin', expression)\n",
    "    expression = re.sub('(?<=a.)-m--ecek-sin', 'mayacaksın', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--ecek-sin', 'mayacaksın', expression)\n",
    "    expression = re.sub('(?<=u.)-m--ecek-sin', 'mayacaksın', expression)\n",
    "    expression = re.sub('(?<=i.)-m--ecek-sin', 'meyeceksin', expression)\n",
    "    expression = re.sub('(?<=e.)-m--ecek-sin', 'meyeceksin', expression)\n",
    "    expression = re.sub('(?<=o.)-m--ecek-sin', 'mayacaksın', expression)\n",
    "    expression = re.sub('(?<=ü.)-m--ecek-im', 'meyeceğim', expression)\n",
    "    expression = re.sub('(?<=ö.)-m--ecek-im', 'meyeceğim', expression)\n",
    "    expression = re.sub('(?<=a.)-m--ecek-im', 'mayacağım', expression)\n",
    "    expression = re.sub('(?<=ı.)-m--ecek-im', 'mayacağım', expression)\n",
    "    expression = re.sub('(?<=u.)-m--ecek-im', 'mayacağım', expression)\n",
    "    expression = re.sub('(?<=i.)-m--ecek-im', 'meyeceğim', expression)\n",
    "    expression = re.sub('(?<=e.)-m--ecek-im', 'meyeceğim', expression)\n",
    "    expression = re.sub('(?<=o.)-m--ecek-im', 'mayacağım', expression)\n",
    "    \n",
    "    expression = re.sub('a-m--di-im', 'amadım', expression)\n",
    "    expression = re.sub('a-m--di-sin', 'amadın', expression)\n",
    "    expression = re.sub('a-m--iyor-sin', 'amıyorsun', expression)\n",
    "    expression = re.sub('a-m--iyor-im', 'amıyorum', expression)\n",
    "\n",
    "    expression = re.sub('e-m--di-im', 'emedim', expression)\n",
    "    expression = re.sub('e-m--di-sin', 'emedin', expression)\n",
    "    expression = re.sub('e-m--iyor-sin', 'emiyorsun', expression)\n",
    "    expression = re.sub('e-m--iyor-im', 'emiyorum', expression)\n",
    "\n",
    "    \n",
    "    expression = re.sub('a-m--ecek-sin', 'amayacaksın', expression)\n",
    "    expression = re.sub('a-m--ecek-im', 'amayacağım', expression)\n",
    "\n",
    "    \n",
    "    expression = re.sub('e-m--ecek-sin', 'emeyeceksin', expression)\n",
    "    expression = re.sub('e-m--ecek-im', 'emeyeceğim', expression)\n",
    "\n",
    "\n",
    "\n",
    " #   expression = re.sub('e-m--ec', 'emeyec', expression)\n",
    "  #  expression = re.sub('a-m--ece', 'amayaca', expression)\n",
    "\n",
    "    expression = re.sub('or-im', 'orum', expression)\n",
    "    expression = re.sub('or-sin', 'orsun', expression)\n",
    "#    expression = re.sub('un-iy', 'unu', expression)\n",
    "    expression = re.sub('un-di', 'undu', expression)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return vh2(vh_n(expression))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9be2637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowelharmony_neg(expression):\n",
    "\n",
    "    expression = re.sub('mdü', 'medi', expression)\n",
    "    expression = re.sub('mdı', 'madı', expression)\n",
    "    expression = re.sub('mdu', 'madı', expression)\n",
    "    expression = re.sub('mdi', 'medi', expression)   \n",
    "    expression = re.sub('mtü', 'medi', expression)\n",
    "    expression = re.sub('mtı', 'madı', expression)\n",
    "    expression = re.sub('mtu', 'madı', expression)\n",
    "    expression = re.sub('mti', 'medi', expression)   \n",
    " \n",
    "\n",
    "\n",
    "    expression = re.sub('mece', 'meyec', expression)\n",
    "    expression = re.sub('mece', 'mayac', expression)  \n",
    "\n",
    "\n",
    "    return expression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "079600e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vh_neg(expression):\n",
    "    return vowelharmony_neg(vowelharmony(expression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "bcd9246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP_nom2 sen)\n",
      "(VP\n",
      "  (NP_acc (N_obj  maymun) -i)\n",
      "  (V_trans (V_stem_trans  siparış et) (Tense -iyor)))\n",
      "(Person2 -sin)\n"
     ]
    }
   ],
   "source": [
    "for s in generate(turkish_grammar, depth=5):\n",
    "    print(s)\n",
    "\n",
    "foo = generate(turkish_grammar, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "43f9db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP_nom1 ben)\n",
      "  (VP (V_intrans (V_stem_intrans  şarkı söyle) (Tense -iyor)))\n",
      "  (Person1 -im))\n"
     ]
    }
   ],
   "source": [
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "e05e3223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koyun acele ediyor\n",
      "sen oklukirpiyi uyarıyorsun\n",
      "sen gergedeni seveceksin\n",
      "sen gergedeni güveniyorsun\n",
      "ben ördeği istedim\n",
      "sen sandalyedeki yemeği tutacaksın\n",
      "ben bekleyeceğim\n",
      "eşeği seveceğim\n",
      "ben ayıyı çalacağım\n",
      "not aldı\n",
      "o gidiyor\n",
      "eşeği sövecek\n",
      "hata yapıyor\n",
      "ayıyı gözlemliyor\n",
      "sen gergedeni güveneceksin\n",
      "ben şaşırıyorum\n",
      "ben yüzüyorum\n",
      "eşeği siparış ediyor\n",
      "ben maymunu gözlemliyorum\n",
      "ben ekmeği siparış ettim\n",
      "sen sandalyedeki ekmeği emrettin\n",
      "ben gorili gözlemliyorum\n",
      "koyun ayıyı çalıyor\n",
      "oklukirpiyi isteyecek\n",
      "o şikayet ediyor\n",
      "kitaptaki gergedeni güveniyor\n",
      "ben imdat istedim\n",
      "ben köşedeki oklukirpiyi saklayacağım\n",
      "sen ördeği tuttun\n",
      "ben gorili görüyorum\n",
      "işçi ayıyı uyaracak\n",
      "kedi dinleniyor\n",
      "ben ördeği kurtardım\n",
      "sen gergedeni kurtardın\n",
      "sen ayıyı görüyorsun\n",
      "eşeği kırdı\n",
      "maymunu uyardı\n",
      "şaşırdı\n",
      "ben gidiyorum\n",
      "not alacak\n",
      "not alacak\n",
      "ben övünüyorum\n",
      "sen övündün\n",
      "köpek izin veriyor\n",
      "sen özür diliyorsun\n",
      "ben sandalyedeki maymunu bulacağım\n",
      "sen imdat istiyorsun\n",
      "o ekmeği seviyor\n",
      "övüneceğim\n",
      "ben ayıyı göreceğim\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50):\n",
    "    print(vowelharmony(\"\".join(generate(turkish_grammar, depth=10).leaves())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2648e",
   "metadata": {},
   "source": [
    "Masadaki kitabı okuyorum\n",
    "I'm reading the book on the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5cf9c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation(grammar):\n",
    "    pos_tree = generate(grammar)\n",
    "    pos = ''.join(pos_tree.leaves())\n",
    "    source = vowelharmony(pos)\n",
    "    target = vowelharmony(pos)\n",
    "    (pos) = 'pos'\n",
    "    (neg) = 'neg'\n",
    "    return source, (pos), target\n",
    "\n",
    "def affirmation(grammar):\n",
    "    pos_tree = generate(grammar)\n",
    "    pos = ''.join(pos_tree.leaves())\n",
    "    neg_tree = negate(pos_tree)\n",
    "    neg = ''.join(neg_tree.leaves())\n",
    "    source = vowelharmony(pos)\n",
    "    target = vowelharmony_n(neg)\n",
    "    (pos) = 'pos'\n",
    "    (neg) = 'neg'\n",
    "    return source, (neg), target\n",
    "\n",
    "def neg_or_pos(grammar, p=.5):\n",
    "    if random.random()<p:\n",
    "        return affirmation(grammar)\n",
    "    else:\n",
    "        return negation(grammar)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd70ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "9131dac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yönetmengülüyor', 'neg', 'yönetmengülmüyor')\n"
     ]
    }
   ],
   "source": [
    "print(neg_or_pos(turkish_grammar, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "577a104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate(t):\n",
    "    symbol = t[0].label().symbol()\n",
    "    if symbol == 'VP':\n",
    "        symbol2 = t[0,0].label().symbol()\n",
    "        if symbol2 == 'NP_acc':\n",
    "            verbstem = t[0,1,0,0]\n",
    "            verbstem = verbstem + '-m-'\n",
    "            t[0,1,0,0] = verbstem    \n",
    "        else:\n",
    "            verbstem = t[0,0,0,0]\n",
    "            verbstem = verbstem + '-m-'\n",
    "            t[0,0,0,0] = verbstem\n",
    "    else:\n",
    "        symbol3 = t[1,0].label().symbol()\n",
    "        if symbol3 == 'NP_acc':\n",
    "            verbstem = t[1,1,0,0]\n",
    "            verbstem = verbstem + '-m-'\n",
    "            t[1,1,0,0] = verbstem\n",
    "        else:\n",
    "            verbstem = t[1,0,0,0]\n",
    "            verbstem = verbstem + '-m-'\n",
    "            t[1,0,0,0] = verbstem\n",
    "    return t\n",
    "\n",
    "#create_file(\"test_file\", neg_grammar, negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e22713fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate(t):\n",
    "    symbol = t[0].label().symbol()\n",
    "    if symbol == 'VP':\n",
    "        symbol2 = t[0,0].label().symbol()\n",
    "        if symbol2 == 'NP_acc':\n",
    "            verbstem = t[0,1,0,0]\n",
    "            verbstem = verbstem + '-m-'\n",
    "            t[0,1,0,0] = verbstem    \n",
    "        else:\n",
    "            verbstem = t[0,0,0,0]\n",
    "            verbstem = verbstem + '-m-'\n",
    "            t[0,0,0,0] = verbstem\n",
    "    else:\n",
    "        symbol3 = t[1,0].label().symbol()\n",
    "        if symbol3 == 'NP_acc':\n",
    "            verbstem = t[1,1,0,0]\n",
    "            verbstem = verbstem + '-m-'\n",
    "            t[1,1,0,0] = verbstem\n",
    "        else:\n",
    "            verbstem = t[1,0,0,0]\n",
    "            verbstem = verbstem + '-m-'\n",
    "            t[1,0,0,0] = verbstem\n",
    "    return t\n",
    "\n",
    "#create_file(\"test_file\", neg_grammar, negation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54e5204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_json(grammar: PCFG, ex_generator: Callable, \n",
    "                        file_prefix: str = '', **splits) -> None:\n",
    "    \"\"\"\n",
    "    Create a dataset json file that can be read using the datasets module's dataset loader.\n",
    "    params: grammar: PCFG: a PCFG object\n",
    "            ex_generator: function: a function that creates a pair of sentences and associated tags\n",
    "                          from the grammar\n",
    "            file_prefix: str: an identifier to add to the beginning of the output file names\n",
    "            splits: a dictionary mapping a string identifying a set label to the number of examples to generate\n",
    "                    for the file with that label\n",
    "                    ex: train = 10000, dev = 1000, test = 10000\n",
    "    output: a file for each argument in splits that contains the specified number of example pairs\n",
    "    \"\"\"\n",
    "    file_prefix = file_prefix + '_' if file_prefix and not file_prefix.endswith('-') and not file_prefix.endswith('_') else ''\n",
    "    \n",
    "    for name, n_examples in splits.items():\n",
    "        l = []\n",
    "        print('Generating examples')\n",
    "        for n in tqdm(range(n_examples)):\n",
    "            source, pfx, target = ex_generator(grammar)\n",
    "            l += [{'translation': {'src': source, 'prefix': pfx, 'tgt': target}}]\n",
    "        \n",
    "        if l:\n",
    "            with gzip.open(file_prefix + name + '.json.gz', 'wt') as f:\n",
    "                print('Saving examples to ' + file_prefix + name + '.json.gz')\n",
    "                for ex in tqdm(l):\n",
    "                    json.dump(ex, f, ensure_ascii=False)\n",
    "                    f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "71db6190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:33<00:00, 3027.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving examples to tu_train.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:01<00:00, 51612.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3144.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving examples to tu_dev.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 45304.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 3094.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving examples to tu_test.json.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 48652.57it/s]\n"
     ]
    }
   ],
   "source": [
    "create_dataset_json(turkish_grammar, neg_or_pos, 'tu', train = 100000, dev = 1000, test = 10000)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39bc51bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f57e77e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ben  bekle di im'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowelharmony('ben  bekle -di -im')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f75d7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "S, S2, NP, MP, AdvP, VPTr, RelP, NPTr, VP, Det, N, PN, Pron, M, VInTr, VTr, NTr, PlDet,PlNTr, RP, V, NTand, Adv, comma = nonterminals('S, S2, NP, MP, AdvP, VPTr, RelP, NPTr, VP, Det, N, PN, Pron, M, VInTr, VTr, NTr, PlDet,PlNTr, RP, V, NTand, Adv, comma')\n",
    "\n",
    "neg_grammar = PCFG.fromstring(\"\"\"\n",
    "    S -> NP MP [0.33] | NP M VPTr RelP [0.33] | AdvP S2 [0.34]\n",
    "    S2 -> NP MP [0.33] | NP M VPTr RelP [0.33] | NTand AdvP S2 [0.34]\n",
    "    NP -> Det N [0.2] | PN [0.6] | Pron [0.2]\n",
    "    MP -> M VInTr [0.5] | M VPTr [0.5]\n",
    "    AdvP -> Adv NP MP comma [1.0]\n",
    "    VPTr -> VTr NPTr  [1.0]\n",
    "    RelP -> RP VP [1.0]\n",
    "    NPTr -> Det NTr [0.5] | PlDet PlNTr [0.5]\n",
    "    VP -> NP V [1.0]\n",
    "    Det -> 'the' [0.5] | 'a' [0.5]\n",
    "    N -> 'student' [0.3] | 'professor' [0.3] | 'wizard' [0.2] | 'witch' [0.2]\n",
    "    PN -> 'Harry' [0.1] | 'Hermione' [0.1] | 'Ron' [0.1] | 'Petunia' [0.05] | 'Vernon' [0.05] | 'Lily' [0.1] | 'James' [0.1] | 'Snape' [0.1] | 'McGonagall' [0.1] | 'Draco' [0.05] | 'Tom' [0.05] | 'Albus' [0.1] \n",
    "    Pron -> 'he' [0.5] | 'she' [0.5]\n",
    "    M -> 'can' [0.2] | 'may' [0.2] | 'must' [0.3] | 'should' [0.3] \n",
    "    VInTr -> 'hiccup' [0.2] | 'party'[0.2] | 'wiggle' [0.1] | 'laugh' [0.1] | 'smile' [0.1] | 'giggle' [0.1] | 'jump' [0.1] | 'run' [0.1]\n",
    "    VTr -> 'prepare' [0.4] | 'make' [0.3] | 'eat' [0.2] | 'sprinkle' [0.1]\n",
    "    NTr -> 'cookie' [0.2] | 'cake' [0.2] | 'chocolate' [0.2] | 'pancake' [0.2] | 'souffle' [0.2]\n",
    "    PlDet -> 'the' [0.8] | 'some' [0.2]\n",
    "    PlNTr -> 'cookies' [0.2] | 'cakes' [0.2] | 'chocolates' [0.2] | 'pancakes' [0.2] | 'souffles' [0.2]\n",
    "    RP -> 'that' [0.6] | 'which' [0.4]\n",
    "    V -> 'loves' [0.2] | 'wants' [0.2] | 'hates' [0.2] | 'likes' [0.2] | 'eats' [0.2]\n",
    "    NTand -> 'and' [1.0]\n",
    "    Adv -> 'because' [0.5] | 'since' [0.5]\n",
    "    comma -> ',' [1.0]   \n",
    "\"\"\")\n",
    "\n",
    "def negation(grammar):\n",
    "    pos_tree = generate(grammar)\n",
    "    pos = ' '.join(pos_tree.leaves())\n",
    "    neg_tree = negate(pos_tree)\n",
    "    neg = ' '.join(neg_tree.leaves())\n",
    "    source = pos\n",
    "    target = neg\n",
    "    (pos) = 'POS: '\n",
    "    (neg) = 'NEG: '\n",
    "    return (pos), source, (neg), target\n",
    " \n",
    "\n",
    "\n",
    "# 3 cases: t[1] can be an M, MP, or an S2\n",
    "# to form the tree, I use recursion. The base case is M or MP and the recursive call happens in the case of S2\n",
    "def negate(t):\n",
    "    symbol = t[1].label().symbol()\n",
    "    # base case 1\n",
    "    if symbol == 'M':\n",
    "        modal = t[1,0]\n",
    "        print(modal)\n",
    "        modal = modal + ' not'\n",
    "        t[1,0] = modal\n",
    "        print(modal)\n",
    "    # base case 2\n",
    "    elif symbol == 'MP':\n",
    "        modal = t[1,0]\n",
    "        print(modal)\n",
    "        modal = modal[-1]\n",
    "        modal = modal + ' not'\n",
    "        t[1,0] = modal\n",
    "        print(modal)\n",
    "    # recursive call\n",
    "    else:\n",
    "        if t[1].label().symbol() == 'AdvP':\n",
    "            negate(t[2])\n",
    "        else:\n",
    "            negate(t[1])  \n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "25d8b531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (PN Draco)) (MP (M should) (VInTr hiccup)))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vowel_harmony' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(generate(neg_grammar, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnegation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneg_grammar\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m foo2 \u001b[38;5;241m=\u001b[39m generate(neg_grammar, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(foo)\n",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36mnegation\u001b[0;34m(grammar)\u001b[0m\n\u001b[1;32m      2\u001b[0m pos_tree \u001b[38;5;241m=\u001b[39m generate(grammar)\n\u001b[1;32m      3\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(pos_tree\u001b[38;5;241m.\u001b[39mleaves())\n\u001b[0;32m----> 4\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[43mvowel_harmony\u001b[49m(pos)\n\u001b[1;32m      5\u001b[0m target \u001b[38;5;241m=\u001b[39m pos\n\u001b[1;32m      6\u001b[0m (pos) \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vowel_harmony' is not defined"
     ]
    }
   ],
   "source": [
    "print(generate(neg_grammar, depth=5))\n",
    "\n",
    "\n",
    "\n",
    "print(negation(neg_grammar))\n",
    "foo2 = generate(neg_grammar, depth=5)\n",
    "print(foo)\n",
    "\n",
    "\n",
    "\n",
    "print(negation(turkish_grammar))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c80f39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tree: Expected a node value and child list ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneg_grammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:25\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(grammar, start, depth)\u001b[0m\n\u001b[1;32m     22\u001b[0m     depth \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmaxsize\n\u001b[1;32m     24\u001b[0m items \u001b[38;5;241m=\u001b[39m [start]\n\u001b[0;32m---> 25\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:38\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     36\u001b[0m total_rule_prob \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod\u001b[38;5;241m.\u001b[39mprob()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m total_rule_prob:\n\u001b[0;32m---> 38\u001b[0m     expansion \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [Tree(i, expansion)]\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:38\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     36\u001b[0m total_rule_prob \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod\u001b[38;5;241m.\u001b[39mprob()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m total_rule_prob:\n\u001b[0;32m---> 38\u001b[0m     expansion \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [Tree(i, expansion)]\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _generate at line 38 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:38\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     36\u001b[0m total_rule_prob \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod\u001b[38;5;241m.\u001b[39mprob()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m total_rule_prob:\n\u001b[0;32m---> 38\u001b[0m     expansion \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [Tree(i, expansion)]\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:39\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m total_rule_prob:\n\u001b[1;32m     38\u001b[0m             expansion \u001b[38;5;241m=\u001b[39m _generate(grammar, prod\u001b[38;5;241m.\u001b[39mrhs(), depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m             result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpansion\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/tree/tree.py:95\u001b[0m, in \u001b[0;36mTree.__init__\u001b[0;34m(self, node, children)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, children\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m children \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: Expected a node value and child list \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(children, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() argument 2 should be a list, not a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    102\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: Tree: Expected a node value and child list "
     ]
    }
   ],
   "source": [
    "print(generate(neg_grammar, depth=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fb2fcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(M must)\n",
      "must not\n",
      "('POS: ', 'she must eat the chocolate', 'NEG: ', 'she must not eat the chocolate')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Tree: Expected a node value and child list ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(negation(neg_grammar))\n\u001b[0;32m----> 2\u001b[0m foo2 \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneg_grammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(foo)\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:25\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(grammar, start, depth)\u001b[0m\n\u001b[1;32m     22\u001b[0m     depth \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmaxsize\n\u001b[1;32m     24\u001b[0m items \u001b[38;5;241m=\u001b[39m [start]\n\u001b[0;32m---> 25\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:38\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     36\u001b[0m total_rule_prob \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod\u001b[38;5;241m.\u001b[39mprob()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m total_rule_prob:\n\u001b[0;32m---> 38\u001b[0m     expansion \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [Tree(i, expansion)]\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:38\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     36\u001b[0m total_rule_prob \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod\u001b[38;5;241m.\u001b[39mprob()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m total_rule_prob:\n\u001b[0;32m---> 38\u001b[0m     expansion \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [Tree(i, expansion)]\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: _generate at line 38 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:38\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     36\u001b[0m total_rule_prob \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod\u001b[38;5;241m.\u001b[39mprob()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m total_rule_prob:\n\u001b[0;32m---> 38\u001b[0m     expansion \u001b[38;5;241m=\u001b[39m \u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrhs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [Tree(i, expansion)]\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CLAY/generator.py:39\u001b[0m, in \u001b[0;36m_generate\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m total_rule_prob:\n\u001b[1;32m     38\u001b[0m             expansion \u001b[38;5;241m=\u001b[39m _generate(grammar, prod\u001b[38;5;241m.\u001b[39mrhs(), depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m             result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpansion\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/tree/tree.py:95\u001b[0m, in \u001b[0;36mTree.__init__\u001b[0;34m(self, node, children)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, children\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m children \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: Expected a node value and child list \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(children, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() argument 2 should be a list, not a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    102\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: Tree: Expected a node value and child list "
     ]
    }
   ],
   "source": [
    "print(negation(neg_grammar))\n",
    "foo2 = generate(neg_grammar, depth=5)\n",
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7086332",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'foo2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(negate(\u001b[43mfoo2\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'foo2' is not defined"
     ]
    }
   ],
   "source": [
    "print(negate(foo2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bbf1ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'foo2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfoo2\u001b[49m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'foo2' is not defined"
     ]
    }
   ],
   "source": [
    "foo2[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ef2e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nicht_grammar import nicht_grammar\n",
    "from nicht_grammar import german_negate\n",
    "from nicht_grammar import negation as german_negation\n",
    "from nltk.parse.generate import generate as nltk_generate\n",
    "\n",
    "\n",
    "S, SInv, S1, SInv1, S2, SInv2, AdvP, \\\n",
    "NPSgNom, NPPlNom, \\\n",
    "NPMascSgNom, NPFemSgNom, NPMascPlNom, NPFemPlNom, \\\n",
    "MPSg, MPPl, MPSgInv, MPPlInv, MPEmbSg, MPEmbPl, \\\n",
    "VP, IVP, TVP, TVPMasc, TVPFem, TVPNeut, \\\n",
    "RelPMasc, RelPFem, RelPNeut, \\\n",
    "NPAcc, NPMascSgAcc, NPFemSgAcc, NPNeutSgAcc, NPMascPlAcc, NPFemPlAcc, NPNeutPlAcc = nonterminals(\n",
    "    'S, SInv, S1, SInv1, S2, SInv2, AdvP, NPSgNom, NPPlNom, NPmascSgNom, ' + \n",
    "    'NPFemSgNom, NPMascPlNom, NPFemPlNom, MPSg, MPPl, MPSgInv, MPPlInv, MPEmbSg, MPEmbPl, ' + \n",
    "    'VP, IVP, TVP, TVPMasc, TVPFem, TVPNeut, RelPMasc, RelPFem, RelPNeut, ' + \n",
    "    'NPAcc, NPMascSgAcc, NPFemSgAcc, NPNeutSgAcc, NPMascPlAcc, NPFemPlAcc, NPNeutPlAcc'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6faff94b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The grammar has rule(s) that yield infinite recursion!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:42\u001b[0m, in \u001b[0;36m_generate_all\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frag1 \u001b[38;5;129;01min\u001b[39;00m _generate_one(grammar, items[\u001b[38;5;241m0\u001b[39m], depth):\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m frag2 \u001b[38;5;129;01min\u001b[39;00m _generate_all(grammar, items[\u001b[38;5;241m1\u001b[39m:], depth):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:57\u001b[0m, in \u001b[0;36m_generate_one\u001b[0;34m(grammar, item, depth)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Nonterminal):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproductions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m _generate_all(grammar, prod\u001b[38;5;241m.\u001b[39mrhs(), depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/grammar.py:589\u001b[0m, in \u001b[0;36mCFG.productions\u001b[0;34m(self, lhs, rhs, empty)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m empty:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lhs_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lhs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_empty_index:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/grammar.py:131\u001b[0m, in \u001b[0;36mNonterminal.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mReturn True if this non-terminal is equal to ``other``.  In\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03mparticular, return True if ``other`` is a ``Nonterminal``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m:rtype: bool\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39m_symbol\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnltk_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnicht_grammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:42\u001b[0m, in \u001b[0;36m_generate_all\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m items:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m frag1 \u001b[38;5;129;01min\u001b[39;00m _generate_one(grammar, items[\u001b[38;5;241m0\u001b[39m], depth):\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m frag2 \u001b[38;5;129;01min\u001b[39;00m _generate_all(grammar, items[\u001b[38;5;241m1\u001b[39m:], depth):\n\u001b[1;32m     44\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m frag1 \u001b[38;5;241m+\u001b[39m frag2\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:58\u001b[0m, in \u001b[0;36m_generate_one\u001b[0;34m(grammar, item, depth)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Nonterminal):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m grammar\u001b[38;5;241m.\u001b[39mproductions(lhs\u001b[38;5;241m=\u001b[39mitem):\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m _generate_all(grammar, prod\u001b[38;5;241m.\u001b[39mrhs(), depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m [item]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:43\u001b[0m, in \u001b[0;36m_generate_all\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frag1 \u001b[38;5;129;01min\u001b[39;00m _generate_one(grammar, items[\u001b[38;5;241m0\u001b[39m], depth):\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m frag2 \u001b[38;5;129;01min\u001b[39;00m _generate_all(grammar, items[\u001b[38;5;241m1\u001b[39m:], depth):\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m frag1 \u001b[38;5;241m+\u001b[39m frag2\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Helpful error message while still showing the recursion stack.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:43\u001b[0m, in \u001b[0;36m_generate_all\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frag1 \u001b[38;5;129;01min\u001b[39;00m _generate_one(grammar, items[\u001b[38;5;241m0\u001b[39m], depth):\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m frag2 \u001b[38;5;129;01min\u001b[39;00m _generate_all(grammar, items[\u001b[38;5;241m1\u001b[39m:], depth):\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m frag1 \u001b[38;5;241m+\u001b[39m frag2\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Helpful error message while still showing the recursion stack.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:42\u001b[0m, in \u001b[0;36m_generate_all\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m items:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m frag1 \u001b[38;5;129;01min\u001b[39;00m _generate_one(grammar, items[\u001b[38;5;241m0\u001b[39m], depth):\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m frag2 \u001b[38;5;129;01min\u001b[39;00m _generate_all(grammar, items[\u001b[38;5;241m1\u001b[39m:], depth):\n\u001b[1;32m     44\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m frag1 \u001b[38;5;241m+\u001b[39m frag2\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:58\u001b[0m, in \u001b[0;36m_generate_one\u001b[0;34m(grammar, item, depth)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Nonterminal):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m grammar\u001b[38;5;241m.\u001b[39mproductions(lhs\u001b[38;5;241m=\u001b[39mitem):\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m _generate_all(grammar, prod\u001b[38;5;241m.\u001b[39mrhs(), depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m [item]\n",
      "    \u001b[0;31m[... skipping similar frames: _generate_all at line 43 (1477 times), _generate_all at line 42 (740 times), _generate_one at line 58 (740 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:42\u001b[0m, in \u001b[0;36m_generate_all\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m items:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m frag1 \u001b[38;5;129;01min\u001b[39;00m _generate_one(grammar, items[\u001b[38;5;241m0\u001b[39m], depth):\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m frag2 \u001b[38;5;129;01min\u001b[39;00m _generate_all(grammar, items[\u001b[38;5;241m1\u001b[39m:], depth):\n\u001b[1;32m     44\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m frag1 \u001b[38;5;241m+\u001b[39m frag2\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:58\u001b[0m, in \u001b[0;36m_generate_one\u001b[0;34m(grammar, item, depth)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Nonterminal):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prod \u001b[38;5;129;01min\u001b[39;00m grammar\u001b[38;5;241m.\u001b[39mproductions(lhs\u001b[38;5;241m=\u001b[39mitem):\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m _generate_all(grammar, prod\u001b[38;5;241m.\u001b[39mrhs(), depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m [item]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:43\u001b[0m, in \u001b[0;36m_generate_all\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frag1 \u001b[38;5;129;01min\u001b[39;00m _generate_one(grammar, items[\u001b[38;5;241m0\u001b[39m], depth):\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m frag2 \u001b[38;5;129;01min\u001b[39;00m _generate_all(grammar, items[\u001b[38;5;241m1\u001b[39m:], depth):\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m frag1 \u001b[38;5;241m+\u001b[39m frag2\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Helpful error message while still showing the recursion stack.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IML/lib/python3.8/site-packages/nltk/parse/generate.py:47\u001b[0m, in \u001b[0;36m_generate_all\u001b[0;34m(grammar, items, depth)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m frag1 \u001b[38;5;241m+\u001b[39m frag2\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;66;03m# Helpful error message while still showing the recursion stack.\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe grammar has rule(s) that yield infinite recursion!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m []\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The grammar has rule(s) that yield infinite recursion!"
     ]
    }
   ],
   "source": [
    "print(next(nltk_generate(nicht_grammar, n=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8459bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(negation(turkish_grammar))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
